{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_day3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOedCAaTYrt2uI2MYyH2co5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanri3/deep_learning_day3_day4/blob/main/deep_learning_day3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nxyQ1mH1lJC"
      },
      "source": [
        "# 深層学習day3 レポート"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tnmR1ZF2w0S"
      },
      "source": [
        "## 1. 再帰型NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecpcggX127pV"
      },
      "source": [
        "### 1.1 RNN（Recurrent Neural Network）\n",
        "時系列データ  \n",
        "時間の経過とともに値が変化していくようなデータ  \n",
        "店舗の日次売上データ，ホームページのアクセス数履歴…etc  \n",
        "\n",
        "確認テスト  \n",
        "RNN 3つの重み  \n",
        "入力 → 中間層  \n",
        "中間層 → 出力  \n",
        "中間層 → 中間層  \n",
        "\n",
        "バイナリ加算  \n",
        "numpy.unpackbits  \n",
        "uint8 配列の要素をバイナリ値の出力配列に展開する。  \n",
        "numpy.uint8  \n",
        ".T 転置行列  \n",
        "numpy.zeros_like(a) = numpy.zeros(a.shape)  \n",
        "但しa：ndarray  \n",
        "\n",
        "numpy.round 四捨五入  \n",
        "スライス ::-1 ndarrayの要素を逆にならべーる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJfKgNLo3cPp"
      },
      "source": [
        "### 1.2 BPTT（backpropagation through time）\n",
        "RNNのネットワークを中間層出力を介して時間方向に展開する方法\n",
        "\n",
        "自然言語処理（RNNの適用例として）\n",
        "Bag-of-Words とは  \n",
        "文章に単語が含まれているかどうかのみを考え、単語の並び方などは考慮しないモデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rooPZqzK3Fgy"
      },
      "source": [
        "## 2. LSTM（Long Short Term Memory）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAJCxasQ3Yk6"
      },
      "source": [
        "RNNは遠い過去の中間層出力を反映するのが難しいという弱点をもっている  \n",
        "それを改善→LSTM  \n",
        "神経科学の短期記憶、長期記憶からヒント  \n",
        "### RNNとの違い  \n",
        "メモリセル：中間層の状態を保持するパラメータ（Constant Error Carrousel：CEC）  \n",
        "\n",
        "Carrousel …  \n",
        "メリーゴーラウンド、回転木馬、(空港で乗客の荷物を運ぶ)回転式コンベヤー  \n",
        "ここでは空港のコンベヤーのイメージか。  \n",
        "\n",
        "重み衝突の問題  \n",
        "重み衝突には入力重み衝突と出力重み衝突があり、  \n",
        "入力層から再帰セルに入力される信号および再帰セルから出力層に入力される信号が、  \n",
        "長期的な特徴をもつのか短期的な特徴を持つのか分からない状態において、  \n",
        "重みを大きさを決定できない問題のこと。\n",
        "\n",
        "重み衝突解決のため、入力ゲート，忘却ゲート，出力ゲートを設ける。\n",
        "\n",
        "忘却ゲート（と呼ばれる関数）：時間経過による各要素の変化を制御  \n",
        "ゲートコントローラ：それぞれのゲートを操作するニューロン。  \n",
        "\n",
        "のぞき穴の結合：ゲート層にセル状態を見させること。  \n",
        "$h(t)$：時刻$t$における出力  \n",
        "\n",
        "https://agirobots.com/lstmgruentrance-noformula/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlQp6F_QWqp3"
      },
      "source": [
        "### 勾配発散（爆発）\n",
        "勾配消失問題 RNNでも起きる。  \n",
        "勾配発散（爆発）問題の解決策  \n",
        "クリッピング … 勾配（の絶対値）がしきい値（threshold）より大きくならない様にする。  \n",
        "\n",
        "活性化関数tanh（Hyperbolic tangent function）  \n",
        "シグモイド関数の微分係数（Derivative： 導関数の出力値）の最大値は0.25と小さいため、勾配が小さくなりがちで学習に時間がかかる。  \n",
        "→ 学習がより高速化するように、微分係数の最大値が1.0となるtanhを"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDRkxOaN1vSU"
      },
      "source": [
        "## 3. GRU（Gated Recurrent Unit）\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYZrJioxlCOw"
      },
      "source": [
        "LSTMと同様の性能を持つとされている。（簡略化した分トレードオフで劣るという見方も）  \n",
        "LSTMより計算量が少なく、高速に学習を進めることができる。\n",
        "\n",
        "LSTMの欠点 … 計算コストが大きい。\n",
        "\n",
        "### 確認テスト：LSTMとの違い  \n",
        "#### 状態ベクトル数を減らした（時間依存の状態数を減らした）\n",
        "LSTMではCECとh(t)の2つが状態を保持 → 1つにまとめる\n",
        "\n",
        "#### ゲートコントローラ数を減らした\n",
        "LSTMでは入力ゲート、忘却ゲート、出力ゲートに1つずつゲートコントローラ（ゲートを操作するニューロン）あり。  \n",
        "→ 忘却ゲートと入力ゲートの操作を1つのコントローラで操作  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ubmVQxH30vv"
      },
      "source": [
        "## 4. 双方向RNN（Bidirectional RNN）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHyEUhxlQ_DX"
      },
      "source": [
        "RNN：ある状態の中間層の出力値を次の状態に順伝播するネットワーク。  \n",
        "Bidirectional RNN：中間層の出力を、未来への順伝播と過去への逆伝播の両方向に伝播するネットワーク。  \n",
        "BRNN では、学習時に、過去と未来の情報の入力を必要とする。  \n",
        "→ 運用時も過去から未来までのすべての情報を入力してはじめて予測できるように。  \n",
        "（そのためBRNNの応用範囲は限定される。）\n",
        "\n",
        "### 順伝播\n",
        "状態 $t$ における中間層は、入力値と状態 $t-1$ から入力を受け取り、  \n",
        "それぞれに重みをかけて、活性化関数に代入して得られる値が出力値となる。\n",
        "\n",
        "### 逆伝播\n",
        "状態 $t$ における中間層は、入力値と状態 $t+1$ から入力を受け取り、  \n",
        "それぞれに重みをかけて、活性化関数に代入して得られる値が出力値となる。\n",
        "\n",
        "### 出力層\n",
        "状態 $t$ における出力層の出力値は、順伝播および逆伝播の中間層の値から計算する。  \n",
        "順伝播の状態を表すベクトル  \n",
        "逆伝播の状態を表すベクトル  \n",
        "これらを縦に結合して一つのベクトルに。  \n",
        "結合後のベクトルに重みをかけ、それを活性化関数に代入して得られる値が出力値となる。  \n",
        "出力層の活性化関数は恒等関数などが使われる。  \n",
        "https://axa.biopapyrus.jp/deep-learning/rnn/brnn.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf6fqpm43922"
      },
      "source": [
        "## 5. Seq2Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gqKJERM2e87"
      },
      "source": [
        "Seq2seqはエンコーダとデコーダから構成されている。  \n",
        "エンコーダは入力系列の各要素を処理し，捉えた情報から「文脈」と呼ばれるベクトルを生成。  \n",
        "デコーダは「文脈」から出力系列の各要素を生成\n",
        "\n",
        "エンコーダとデコーダはどちらもRNNである。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG3TThChqqaP"
      },
      "source": [
        "### EncorderRNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyXnRAmiB0gp"
      },
      "source": [
        "Tokenize  \n",
        "文章を単語（token と呼ぶ）毎に分割  \n",
        "↓  \n",
        "Embedding  \n",
        "tokenを分散表現ベクトルに変換  \n",
        "↓  \n",
        "ベクトルを RNN に入力"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOkaV_5BqyYh"
      },
      "source": [
        "### DecorderRNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBuRrWy-Ddsy"
      },
      "source": [
        "Encoder RNN が出力したベクトルから、各 token の生成確率を出力  \n",
        "↓  \n",
        "生成確率を重みとして token をランダムに選択（重み付き）しEmbedding。  \n",
        "↓  \n",
        "ベクトルを RNN に入力"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QnPnmGWF9oF"
      },
      "source": [
        "### HRED（Hierarchical Recurrent Encoder-Decoder）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDxefQGxC-zN"
      },
      "source": [
        "Seq2Seq：一問一答  \n",
        "HRED過去の n-1 個の発話から次の n 個目の発話を推測するようにした   \n",
        "\n",
        "Seq2Seq は Encoder RNN, Decoder RNN の2段構成  \n",
        "HRED は Encoder RNN, Context RNN, Decoder RNN の3段構成  \n",
        "\n",
        "Encoder RNN：個々の文章をベクトルに変換  \n",
        "Context RNN：Encoder の出力をまとめて会話コンテキスト全体を表すベクトルに変換  \n",
        "Decoder RNN：Context RNN の情報から応答を生成  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdduCuIrY-rM"
      },
      "source": [
        "### VHRED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaOjLXboZES0"
      },
      "source": [
        "HRED + VAEの潜在変数の概念 ＝ VHRED  \n",
        "\n",
        "過去の n-1 個の発話を与えられて、 n 個目の発話を生成（HRED と同じ）  \n",
        "HRED は、対話学習において以下の問題が…  \n",
        "\n",
        "HRED は確率的な多様性が字面だけ。会話の流れに多様性が無い。  \n",
        "Encoder RNN, Context RNN, Decoder RNN のうち確率的な処理が Decoder RNN の次ステップの単語を生成する部分にしか無い。  \n",
        "→ 同じコンテキストを与えられると毎回会話の流れが同じに  \n",
        "\n",
        "HRED は短く情報量に乏しい答えをしがち  \n",
        "\n",
        "現実には、同じコンテキストを与えられても、それに続く発話は全く異なるものになり得る。  \n",
        "「やあ！おはよう」 に対し 「いい天気だね」 も 「最近どう？」も会話として成立  \n",
        "だがHREDは短いよくある答えを学ぶ傾向（「うん」「そうだね」「…」など）  \n",
        "\n",
        "VHRED では Context RNN の部分に確率的なノイズを与えて学習し解決  \n",
        "\n",
        "VHRED は会話の流れを表す Context RNN にノイズを乗せる  \n",
        "→ 同じコンテキストに対しても字面だけではない多様な返答が可能\n",
        "VHRED はコンテキストに対する返答のばらつきを Context RNN の確率的な幅で吸収"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsINVZeu4QWn"
      },
      "source": [
        "## 6. Word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqn-8bPDfnIK"
      },
      "source": [
        "自然言語処理の手法  \n",
        "文章中の単語を数値ベクトルに変換（word to vector!）してその意味を把握\n",
        "\n",
        "設計思想  \n",
        "「同じ文脈に現れる単語は類似した意味を持つ」という分布仮説  \n",
        "\n",
        "単語をベクトルで表現する手法  \n",
        "・one-hot表現  \n",
        "・分散表現 … Word2vecではこちらを使用。もう、すっごい多次元のベクトル。こんなでほんまにエエんかって思うわ正直。ええんやろけど。\n",
        "\n",
        "Word2vecに搭載されている2つのニューラルネットワーク・モデル  \n",
        "・CBoW（Continuous Bag-of-Words Model）…周囲の単語からある単語を予測（速い）  \n",
        "・Skip-gram（Continuous Skip-Gram Model）…ある単語からその周囲の単語を予測（正確）\n",
        "\n",
        "https://ainow.ai/2021/04/08/254071/\n",
        "\n",
        "https://deepage.net/bigdata/machine_learning/2016/09/02/word2vec_power_of_word_vector.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bySeMv6c4bSo"
      },
      "source": [
        "## 7. Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFywTHe7t0Cd"
      },
      "source": [
        "### 確認テスト：Seq2SeqとAttention\n",
        "Seq2Seqの「文脈」ベクトルでは長文を扱うのが困難 → seq2seqのボトルネックに  \n",
        "\n",
        "### Attentionとは\n",
        "文章中のどの単語に注目すればよいのかを表すスコア  \n",
        "#### Query  \n",
        "入力された単語群。  \n",
        "#### 索引Memory  \n",
        "索引で引かれた単語群。Key，Valueの2つに分離される。  \n",
        "#### Key  \n",
        "関連度を計算。  \n",
        "#### Value  \n",
        "関連度に従って取得。  \n",
        "\n",
        "### Attentionには複数の種類が\n",
        "#### Self-Attention  \n",
        "InputとMemoryが同一のAttention。  \n",
        "#### SourceTarget-Attention  \n",
        "InputとMemoryが異なるAttention。  \n",
        "\n",
        "### Transformer\n",
        "Multi-Head Attention  \n",
        "Attentionを並列に並べて性能を向上をはかったもの。\n",
        "\n",
        "### Bert\n",
        "双方向Transformer\n",
        "\n",
        "https://www.ydc.co.jp/column/0002/20191118.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na20tg_q1DRM"
      },
      "source": [
        "## BLEU（Bilingual Evaluation Understudy）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZVKqZh81duA"
      },
      "source": [
        "BLEUスコア（自動評価尺度） … \n",
        "機械翻訳の評価に広く用いられている\n",
        "\n",
        "参照訳 … 正解訳のことらしい  \n",
        "BP（brevity penalty）  \n",
        "\n",
        "n-gramとは … 連続するn個の単語や文字のまとまり\n",
        "\n",
        "https://to-in.com/blog/101191"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTIf0ef3yYhQ"
      },
      "source": [
        "##クロスバリデーション（Cross-validation，交差検証）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40mQc4cJyh-R"
      },
      "source": [
        "認定テスト問79  \n",
        "K-分割交差検証 … データをK個に分割 → そのうち1つをテストデータに、  \n",
        "残りのK-1個を学習データとして正解率を評価  \n",
        "これをK個のデータすべてが1回ずつテストデータになるようにK回学習を行ない、  \n",
        "精度の平均をとる手法。\n",
        "\n",
        "ホールドアウト  \n",
        "\n",
        "https://aiacademy.jp/media/?p=263"
      ]
    }
  ]
}