{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_hands_on_01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanri3/deep_learning_day3_day4/blob/main/pytorch_hands_on_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4JztMOxNIvu"
      },
      "source": [
        "# 連載『PyTorch入門』のノートブック（1）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNzlYFotSTzy"
      },
      "source": [
        "※上から順に実行してください。上のコードで実行したものを再利用しているところがあるため、すべて実行しないとエラーになるコードがあります。  \n",
        "　すべてのコードを一括実行したい場合は、メニューバーから［ランタイム］－［すべてのセルを実行］をクリックしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8psaSQlSFN9"
      },
      "source": [
        "※「Python 3」を利用してください。  \n",
        "　Python 3を利用するには、メニューバーから［ランタイム］－［ランタイムのタイプを変更］を選択すると表示される［ノートブックの設定］ダイアログの、［ランタイムのタイプ］欄で「Python 3」に選択し、その右下にある［保存］ボタンをクリックしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ueKLtX95oVW"
      },
      "source": [
        "# 第1回　難しくない！　PyTorchでニューラルネットワークの基本"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_E3IdevRyna"
      },
      "source": [
        "## ■PyTorchとは？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQwqGYlhR7-J"
      },
      "source": [
        "- 人気急上昇中（参考：「[PyTorch vs. TensorFlow、ディープラーニングフレームワークはどっちを使うべきか問題 (1/2)：気になるニュース＆ネット記事 - ＠IT](https://www.atmarkit.co.jp/ait/articles/1910/31/news028.html)）」\n",
        "- Pythonic（＝Pythonのイディオムをうまく活用した自然なコーディングが可能）\n",
        "- 柔軟性や拡張性に優れる（特に“define-by-run”：実行しながら定義／eager execution：即時実行なので、例えばモデルのフォワードプロパゲーション（順伝播）時にif条件やforループなどの制御フローを書いて動的に計算グラフを変更したりできる）\n",
        "\n",
        "特にNLP（Natural Language Processing：自然言語処理）の分野では、研究者はさまざまな長さの文を訓練する必要性があるため、動的な計算グラフが不可欠。実際に「PyTorchがデファクトスタンダードになっている」と筆者が初めて聞いたのは、NLPに関しての話だった。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJdujIPyYdDT"
      },
      "source": [
        "## ■本稿の目的と方針"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Grrfk74Yl7a"
      },
      "source": [
        "PyTorchでニューラルネットワークを定義するための最重要の基礎知識を最短で紹介する。\n",
        "\n",
        "- PyTorchのチュートリアルは最初からCNNで最初から複雑（※これはある程度のニューラルネットワークの知識がない人を門前払いする意味があると思う）\n",
        "- まずはニューラルネットワークの原型「ニューロン」を実装することで、核となる機能を理解する\n",
        "- 「ニューロン」「活性化関数」「正則化」「勾配」「確率的勾配降下法（SGD）」といった概念が分からない場合は、『[TensorFlow 2＋Keras（tf.keras）入門 - ＠IT](https://www.atmarkit.co.jp/ait/subtop/features/di/tf2keras_index.html)』の第1回～第3回で挙動を示しながら分かりやすく説明しているので、先にそちらを一読してほしい\n",
        "- 最終的には、基本的なニューラルネットワーク＆ディープラーニングのコードが思いどおりに書けるようになる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzMyXEPUNmKU"
      },
      "source": [
        "## ■本稿で説明する大まかな流れ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFOYuPJ6Ngnu"
      },
      "source": [
        "- （1）ニューロンのモデル定義\n",
        "- （2）フォワードプロパゲーション（順伝播）\n",
        "- （3）バックプロパゲーション（逆伝播）と自動微分（Autograd）\n",
        "- （4）PyTorchの基礎： テンソルとデータ型\n",
        "- （5）データセットとデーターローダー（DataLoader）\n",
        "- （6）ディープニューラルネットのモデル定義\n",
        "- （7）学習／最適化（オプティマイザー）\n",
        "- （8）評価／精度検証"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMC_Xm6Ouqk9"
      },
      "source": [
        "## ■（1）ニューロンのモデル定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMboLmdvjYaq"
      },
      "source": [
        "###  【チェック】Pythonバージョン（※3系を使うこと）\n",
        "Colabにインストール済みのものを使う。もし2系になっている場合は、メニューバーの［ランタイム］－［ランタイムのタイプを変更］をクリックして切り替えてほしい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SziRZWCujWXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69cba503-4e45-4756-b9bf-d856f3ba4263"
      },
      "source": [
        "import sys\n",
        "print('Python', sys.version)\n",
        "# Python 3.6.9 (default, Nov  7 2019, 10:44:02)  …… などと表示される"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.11 (default, Jul  3 2021, 18:01:19) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDCm1WGuu2OW"
      },
      "source": [
        "###  【チェック】PyTorchバージョン\n",
        "基本的にはColabにインストール済みのものを使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EuZVjZZu663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc96b36c-4769-45f0-d59d-78225ac81bb3"
      },
      "source": [
        "import torch\n",
        "print('PyTorch', torch.__version__)\n",
        "# PyTorch 1.3.1 ……などと表示される"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch 1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYTu1liZvPUq"
      },
      "source": [
        "### リスト1-0　［オプション］ライブラリ「PyTorch」最新バージョンのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3ruhTNMvUQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7914da4-8f52-495c-8ba9-baba51280b88"
      },
      "source": [
        "#!pip install torch        # ライブラリ「PyTorch」をインストール\n",
        "#!pip install torchvision  # 画像／ビデオ処理のPyTorch用追加パッケージもインストール\n",
        "\n",
        "# 最新バージョンにアップグレードする場合\n",
        "!pip install --upgrade torch torchvision\n",
        "\n",
        "# バージョンを明示してアップグレードする場合\n",
        "#!pip install --upgrade torch===1.4.0 torchvision===0.5.0\n",
        "\n",
        "# 最新バージョンをインストールする場合\n",
        "#!pip install torch torchvision\n",
        "\n",
        "# バージョンを明示してインストールする場合\n",
        "#!pip install torch===1.4.0 torchvision===0.5.0"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDCmbMXF490y"
      },
      "source": [
        "このコードのポイント：\n",
        "- 「torchvision」パッケージは本稿では使っていないが、同時にインストールしないとパッケージ関係が不整合となるため、インストールしておく必要がある\n",
        "- 実行後にランタイムを再起動する必要がある"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzWIxm9wwfpZ"
      },
      "source": [
        "### ［オプション］【チェック】PyTorchバージョン（※インストール後の確認）\n",
        "バージョン1.4.0以上になっているか再度チェックする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTgmXjFewkVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbbb7cae-9fef-4c23-e113-d1ccb53f5c9b"
      },
      "source": [
        "import torch\n",
        "print('PyTorch', torch.__version__)\n",
        "# PyTorch 1.4.0 ……などと表示される"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch 1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3nDS-MFxo06"
      },
      "source": [
        "### リスト1-1　ニューロンのモデル設計と活性化関数\n",
        "\n",
        "- ニューロンへの入力＝$(w_1 \\times X_1)+(w_2 \\times X_2)+b$\n",
        "- ニューロンからの出力＝$a((w_1 \\times X_1)+(w_2 \\times X_2)+b)$\n",
        "  - $a()$は活性化関数を意味する。つまりニューロンの入力結果を、活性化関数で変換したうえで、出力する\n",
        "  - 今回の活性化関数は、**tanh**関数とする\n",
        "- ニューロンの構造とデータ入力：座標$(X_1, X_2)$\n",
        "  - 入力の数（`INPUT_FEATURES`）は、$X_1$と$X_2$で**2つ**\n",
        "  - ニューロンの数（`OUTPUT_NEURONS`）は、**1つ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uu-jPQOxy2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f410674-8d97-4f16-fea4-6e18fe14b43b"
      },
      "source": [
        "import torch       # ライブラリ「PyTorch」のtorchパッケージをインポート\n",
        "import torch.nn as nn  # 「ニューラルネットワーク」モジュールの別名定義\n",
        "\n",
        "# 定数（モデル定義時に必要となるもの）\n",
        "INPUT_FEATURES = 2  # 入力（特徴）の数： 2\n",
        "OUTPUT_NEURONS = 1  # ニューロンの数： 1\n",
        "\n",
        "# 変数（モデル定義時に必要となるもの）\n",
        "activation = torch.nn.Tanh()  # 活性化関数： tanh関数\n",
        "\n",
        "# 「torch.nn.Moduleクラスのサブクラス化」によるモデルの定義\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # 層（layer：レイヤー）を定義\n",
        "        self.layer1 = nn.Linear(  # Linearは「全結合層」を指す\n",
        "            INPUT_FEATURES,       # データ（特徴）の入力ユニット数\n",
        "            OUTPUT_NEURONS)       # 出力結果への出力ユニット数\n",
        "\n",
        "    def forward(self, input):\n",
        "        # フォワードパスを定義\n",
        "        output = activation(self.layer1(input))  # 活性化関数は変数として定義\n",
        "        # 「出力＝活性化関数（第n層（入力））」の形式で記述する。\n",
        "        # 層（layer）を重ねる場合は、同様の記述を続ければよい（第3回＝後述）。\n",
        "        # 「出力（output）」は次の層（layer）への「入力（input）」に使う。\n",
        "        # 慣例では入力も出力も「x」と同じ変数名で記述する（よって以下では「x」と書く）\n",
        "        return output\n",
        "\n",
        "# モデル（NeuralNetworkクラス）のインスタンス化\n",
        "model = NeuralNetwork()\n",
        "model   # モデルの内容を出力"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (layer1): Linear(in_features=2, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9COzxIQFzqJQ"
      },
      "source": [
        "このコードのポイント：\n",
        "- `torch.nn.Module`クラスを継承して独自にモデル用クラスを定義する。Pythonの「モジュール」と紛らわしいので、本稿では「`torch.nn.Module`」と表記する\n",
        "    - `__init__`関数にレイヤー（層）を定義する\n",
        "    - `forward`関数にフォワードパス（＝活性化関数で変換しながらデータを流す処理）を実装する\n",
        "    - ちなみにバックプロパゲーション（誤差逆伝播）のための`backward`関数は自動微分機能により自動作成される（後述）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZmXJJjRA5RI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2fc45308-436a-45a5-f880-ef8cdff1a795"
      },
      "source": [
        "#@title tanh関数\n",
        "# This code will be hidden when the notebook is loaded.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "x = np.arange(-6.0, 6.0, 0.001)\n",
        "plt.plot(x, sigmoid(x), label = \"Sigmoid\")\n",
        "plt.plot(x, tanh(x), label = \"tanh\")\n",
        "plt.xlim(-6, 6)\n",
        "plt.ylim(-1.2, 1.2)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxdAFpl2TYr7"
      },
      "source": [
        "- PyTorchでは、以下の活性化関数が用意されている\n",
        "  - ELU\n",
        "  - Hardshrink\n",
        "  - Hardtanh\n",
        "  - LeakyReLU\n",
        "  - LogSigmoid\n",
        "  - MultiheadAttention\n",
        "  - PReLU\n",
        "  - ReLU（有名）\n",
        "  - ReLU6\n",
        "  - RReLU\n",
        "  - SELU\n",
        "  - CELU\n",
        "  - GELU\n",
        "  - Sigmoid（シグモイド）\n",
        "  - Softplus（ソフトプラス）\n",
        "  - Softshrink\n",
        "  - Softsign（ソフトサイン）\n",
        "  - Tanh（本稿で使用）\n",
        "  - Tanhshrink\n",
        "  - Threshold\n",
        "  - Softmin\n",
        "  - Softmax\n",
        "  - Softmax2d\n",
        "  - LogSoftmax\n",
        "  - AdaptiveLogSoftmaxWithLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bp5s_s611Lq"
      },
      "source": [
        "### リスト1-2　パラメーター（重みとバイアス）の初期値設定\n",
        "\n",
        "- $w_1=0.6$、$w_2=-0.2$、$b=0.8$と仮定して、ニューロンのモデルを定義\n",
        "  - ※これらの値は通常は学習により決定されるが、今回は未学習なので仮の固定数値としている\n",
        "  - 重さ（$w_1$と$w_2$）は2次元配列でまとめて表記する： `weight_array`\n",
        "    - 通常は、ニューロンは複数あるので、2次元配列で表記する\n",
        "    - 複数の重みが「行」を構成し、複数のニューロンが「列」を構成する\n",
        "    - 今回は、重みが**2つ**で、ニューロンが**1つ**なので、**2行1列**で記述する\n",
        "    -  `[[ 0.6],`<br>&nbsp;&nbsp;`[-0.2]]`\n",
        "  - バイアス（$b$）は1次元配列でまとめて表記する： `bias_array`\n",
        "    - `[0.8]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe3iD9H91qON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40fd2eb-be23-407b-f2b9-61585e12af62"
      },
      "source": [
        "# パラメーター（ニューロンへの入力で必要となるもの）の定義\n",
        "weight_array = nn.Parameter(\n",
        "    torch.tensor([[ 0.6,\n",
        "                   -0.2]]))  # 重み\n",
        "bias_array = nn.Parameter(\n",
        "    torch.tensor([  0.8 ]))  # バイアス\n",
        "\n",
        "# 重みとバイアスの初期値設定\n",
        "model.layer1.weight = weight_array\n",
        "model.layer1.bias = bias_array\n",
        "\n",
        "# torch.nn.Module全体の状態を辞書形式で取得\n",
        "params = model.state_dict()\n",
        "#params = list(model.parameters()) # このように取得することも可能\n",
        "params\n",
        "# 出力例：\n",
        "# OrderedDict([('layer1.weight', tensor([[ 0.6000, -0.2000]])),\n",
        "#              ('layer1.bias', tensor([0.8000]))])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer1.weight', tensor([[ 0.6000, -0.2000]])),\n",
              "             ('layer1.bias', tensor([0.8000]))])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQOf7w_K30L9"
      },
      "source": [
        "このコードのポイント：\n",
        "- モデルのパラメーターは`torch.nn.Parameter`オブジェクトとして定義する\n",
        "  - `torch.nn.Parameter`クラスのコンストラクター（厳密には`__init__`関数）には`torch.Tensor`オブジェクト（以下、テンソル）を指定する\n",
        "  - `torch.Tensor`のコンストラクターにはPythonの多次元リストを指定できる\n",
        "  - NumPyの多次元配列からのテンソルの作成や、テンソルの使い方については第2回（＝後述）\n",
        "- 重みやバイアスの初期値設定：\n",
        "  - `＜モデル名＞.＜レイヤー名＞.weight`プロパティに重みが指定できる\n",
        "  - `＜モデル名＞.＜レイヤー名＞.baias`プロパティにバイアスが指定できる\n",
        "  - 通常は「**0**」や「一様分布の**ランダムな値**」などを指定する（第3回＝後述）\n",
        "- 重みやバイアスといったパラメーターなどの`torch.nn.Module`全体の状態は、`＜モデル名＞.state_dict()`メソッドで取得できる\n",
        "  - ちなみにパラメーターを最適化で使う際は、`＜モデル名＞.parameters()`メソッドで取得する（第3回＝後述）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuu22vpliye3"
      },
      "source": [
        "## ■（2）フォワードプロパゲーション（順伝播）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd1IafG72_SS"
      },
      "source": [
        "### リスト2-1　フォワードプロパゲーションの実行と結果確認\n",
        "- ニューロンに、座標$(X_1, X_2)$データを入力する\n",
        "  - 通常のデータは表形式（＝2次元配列）だが、今回は$(1.0, 2.0)$という1つのデータ\n",
        "    - 1つのデータでも2次元配列（具体的には**1行2列**）で表現する必要がある"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ0vt-HN3HVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e7983d-d4c4-4522-da7e-33e672120049"
      },
      "source": [
        "X_data = torch.tensor([[1.0, 2.0]])  # 入力する座標データ（1.0、2.0）\n",
        "print(X_data)\n",
        "# tensor([[1., 2.]]) ……などと表示される\n",
        "\n",
        "y_pred = model(X_data)  # このモデルに、データを入力して、出力を得る（＝予測：predict）\n",
        "print(y_pred)\n",
        "# tensor([[0.7616]], grad_fn=<TanhBackward>) ……などと表示される"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.]])\n",
            "tensor([[0.7616]], grad_fn=<TanhBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eg6v2OEmg8x"
      },
      "source": [
        "このコードのポイント：\n",
        "- フォワードプロパゲーション（順伝播）で、データ（`X_data`）を入力し、モデル（`model`）が推論した結果（`y_pred`）を出力している\n",
        "- その結果の数値は、手動で計算した値（`0.7616`）と同じになるのが確認できるはず\n",
        "- `grad_fn`属性（この例では「TanhBackward」）には、勾配（偏微分）などを計算するための関数が自動作成されている。バックプロパゲーション（逆伝播）による学習の際に利用される"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHxRfDZfjOiq"
      },
      "source": [
        "### リスト2-2　動的な計算グラフの可視化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0Mo-cBPlFqB"
      },
      "source": [
        "「[torchviz · PyPI](https://pypi.org/project/torchviz/)」をインストールして、動的な計算グラフ（dynamic computation graph）を可視化する。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luqbk_p352Qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a9e39a-2655-4a39-8a91-901a2a3628f9"
      },
      "source": [
        "!pip install torchviz          # 初回の「torchviz」パッケージインストール時にのみ必要"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.7/dist-packages (0.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPPHf3GGhUBS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "f98471eb-d90f-4378-d842-69b7a601bc14"
      },
      "source": [
        "from torchviz import make_dot  # 「torchviz」モジュールから「make_dot」関数をインポート\n",
        "make_dot(y_pred, params=dict(model.named_parameters()))\n",
        "# 引数「params」には、全パラメーターの「名前: テンソル」の辞書を指定する。\n",
        "# 「dict(model.named_parameters())」はその辞書を取得している"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f76e33aefd0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"218pt\" height=\"336pt\"\n viewBox=\"0.00 0.00 218.00 336.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 332)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-332 214,-332 214,4 -4,4\"/>\n<!-- 140148595531040 -->\n<g id=\"node1\" class=\"node\">\n<title>140148595531040</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"133,-31 74,-31 74,0 133,0 133,-31\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1, 1)</text>\n</g>\n<!-- 140148595472528 -->\n<g id=\"node2\" class=\"node\">\n<title>140148595472528</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"148,-86 59,-86 59,-67 148,-67 148,-86\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TanhBackward</text>\n</g>\n<!-- 140148595472528&#45;&gt;140148595531040 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140148595472528&#45;&gt;140148595531040</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M103.5,-66.9688C103.5,-60.1289 103.5,-50.5621 103.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.0001,-41.3678 103.5,-31.3678 100.0001,-41.3678 107.0001,-41.3678\"/>\n</g>\n<!-- 140148595471440 -->\n<g id=\"node3\" class=\"node\">\n<title>140148595471440</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-141 56,-141 56,-122 151,-122 151,-141\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140148595471440&#45;&gt;140148595472528 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140148595471440&#45;&gt;140148595472528</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M103.5,-121.9197C103.5,-114.9083 103.5,-105.1442 103.5,-96.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.0001,-96.3408 103.5,-86.3408 100.0001,-96.3409 107.0001,-96.3408\"/>\n</g>\n<!-- 140148595470544 -->\n<g id=\"node4\" class=\"node\">\n<title>140148595470544</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140148595470544&#45;&gt;140148595471440 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140148595470544&#45;&gt;140148595471440</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M59.7319,-176.9197C67.2391,-169.1293 78.021,-157.9405 87.0049,-148.6176\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.5983,-150.9703 94.017,-141.3408 84.5578,-146.113 89.5983,-150.9703\"/>\n</g>\n<!-- 140148620213776 -->\n<g id=\"node5\" class=\"node\">\n<title>140148620213776</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"91,-262 8,-262 8,-232 91,-232 91,-262\"/>\n<text text-anchor=\"middle\" x=\"49.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">layer1.bias</text>\n<text text-anchor=\"middle\" x=\"49.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140148620213776&#45;&gt;140148595470544 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140148620213776&#45;&gt;140148595470544</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M49.7523,-231.7333C49.8796,-224.0322 50.0356,-214.5977 50.172,-206.3414\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"53.6757,-206.1429 50.3415,-196.0864 46.6767,-206.0272 53.6757,-206.1429\"/>\n</g>\n<!-- 140148595470800 -->\n<g id=\"node6\" class=\"node\">\n<title>140148595470800</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"193,-196 122,-196 122,-177 193,-177 193,-196\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140148595470800&#45;&gt;140148595471440 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140148595470800&#45;&gt;140148595471440</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M148.0939,-176.9197C140.4451,-169.1293 129.4597,-157.9405 120.3064,-148.6176\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"122.6653,-146.0244 113.1619,-141.3408 117.6704,-150.9286 122.6653,-146.0244\"/>\n</g>\n<!-- 140148595471952 -->\n<g id=\"node7\" class=\"node\">\n<title>140148595471952</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"210,-256.5 109,-256.5 109,-237.5 210,-237.5 210,-256.5\"/>\n<text text-anchor=\"middle\" x=\"159.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140148595471952&#45;&gt;140148595470800 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140148595471952&#45;&gt;140148595470800</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M159.1787,-237.2796C158.9062,-229.0376 158.5065,-216.9457 158.1654,-206.629\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"161.6558,-206.2761 157.8272,-196.3972 154.6596,-206.5074 161.6558,-206.2761\"/>\n</g>\n<!-- 140148620395376 -->\n<g id=\"node8\" class=\"node\">\n<title>140148620395376</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"207,-328 112,-328 112,-298 207,-298 207,-328\"/>\n<text text-anchor=\"middle\" x=\"159.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">layer1.weight</text>\n<text text-anchor=\"middle\" x=\"159.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1, 2)</text>\n</g>\n<!-- 140148620395376&#45;&gt;140148595471952 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140148620395376&#45;&gt;140148595471952</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M159.5,-297.6924C159.5,-288.5067 159.5,-276.7245 159.5,-266.8312\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"163.0001,-266.703 159.5,-256.7031 156.0001,-266.7031 163.0001,-266.703\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9TQTF59l8AK"
      },
      "source": [
        "この図のポイント：\n",
        "- 青色のボックス： 勾配を計算する必要がある、重みやバイアスなどのパラメーター。この例では`(1, 2)`が重みで、`(1)`がバイアス\n",
        "- 灰色のボックス： 勾配（偏微分）などを計算するための関数。「テンソル」データの`grad_fn`属性（この例では「TBackward」や「AddmmBackward」）に自動作成されている。バックプロパゲーション（逆伝播）による学習の際に利用される\n",
        "- 緑色のボックス： グラフ計算の開始点。`backward()`メソッドを呼び出すと、ここから逆順に計算していく。内容は灰色のボックスと同じ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFwzuitssETB"
      },
      "source": [
        "## ■（3）バックプロパゲーション（逆伝播）と自動微分（Autograd）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_trGfyZBB0jX"
      },
      "source": [
        "### リスト3-1　簡単な式で自動微分してみる\n",
        "\n",
        "`backward()`メソッドでバックプロパゲーション（誤差逆伝播）をさせる。ニューラルネットワークの誤差逆伝播では、「微分係数（derivative）の計算」という面倒くさい処理が待っている。ディープラーニングのライブラリは、この処理を自動化してくれるので大変便利である。この機能を「自動微分（AD： Automatic differentiation）」や「Autograd」（gradients computed automatically： 自動計算された勾配）などと呼ぶ。\n",
        "\n",
        "ちなみに詳細を知る必要はあまりないが、`torch.autograd`モジュールは厳密には「リバースモードの自動微分」機能を提供しており、vector-Jacobian product（VJP：ベクトル-ヤコビアン積）と呼ばれる計算を行うエンジンである（参考「[Autograd: Automatic Differentiation — PyTorch Tutorials 1.4.0 documentation](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)」、論文「[Automatic differentiation in PyTorch | OpenReview](https://openreview.net/forum?id=BJJsrmfCZ)」）。\n",
        "\n",
        "PyTorchの自動微分（Autograd）機能を、非常にシンプルな例で示しておく。\n",
        "\n",
        "- 計算式： $y=x^2$\n",
        "- 導関数： $\\frac{dy}{dx}=2x$ （ $y$ を $x$ で微分する）\n",
        "- 例えば $x$ が__1.0__の地点の勾配（＝接線の傾き）は__2.0__となる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-lnNEoOEYfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb2d635-b99a-4e4f-a8fd-b01987a82a13"
      },
      "source": [
        "x = torch.tensor(1.0, requires_grad=True)  # 今回は入力に勾配（gradient）を必要とする\n",
        "# 「requires_grad」が「True」（デフォルト：False）の場合、\n",
        "# torch.autogradが入力テンソルに関するパラメーター操作（勾配）を記録するようになる\n",
        "\n",
        "#x.requires_grad_(True)  # 「requires_grad_()」メソッドで後から変更することも可能\n",
        "\n",
        "y = x ** 2     # 「yイコールxの二乗」という計算式の計算グラフを構築\n",
        "print(y)       # tensor(1., grad_fn=<PowBackward0>) ……などと表示される\n",
        "\n",
        "y.backward()   # 逆伝播の処理として、上記式から微分係数（＝勾配）を計算（自動微分：Autograd）\n",
        "\n",
        "g = x.grad     # 与えられた入力（x）によって計算された勾配の値（grad）を取得\n",
        "print(g)       # tensor(2.)  ……などと表示される\n",
        "# 計算式の微分係数（＝勾配）を計算するための導関数は「dy/dx=2x」なので、\n",
        "#「x=1.0」地点の勾配（＝接線の傾き）は「2.0」となり、出力結果は正しい。\n",
        "# 例えば「x=0.0」地点の勾配は「0.0」、「x=10.0」地点の勾配は「20.0」である"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKBUuoYOTnH4"
      },
      "source": [
        "このコードのポイント：\n",
        "- PyTorchが「自動微分」機能を持つライブラリであることが確認できた\n",
        "- 出力されたテンソル（`y`）の`backward()`メソッドでバックプロパゲーション（逆伝播）を実行できる。なお、ニューラルネットワークの場合は、損失を表すテンソルの`backward()`メソッドを呼び出すことになる\n",
        "  - 出力されたテンソルの計算式（`y`）を入力したテンソル(`x`)で微分計算している\n",
        "- 計算された微分係数（＝勾配：gradient）は、入力したテンソルの`grad`プロパティで取得できる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtesDEFJoHLZ"
      },
      "source": [
        "### リスト3-2　ニューラルネットワークにおける各パラメーターの勾配"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbQ1R6nKnwoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bc5baf-12a2-496f-98d0-fdbeabe861d6"
      },
      "source": [
        "# 勾配計算の前に、各パラメーター（重みやバイアス）の勾配の値（grad）をリセットしておく\n",
        "model.layer1.weight.grad = None      # 重み\n",
        "model.layer1.bias.grad = None        # バイアス\n",
        "#model.zero_grad()                   # これを呼び出しても上記と同じくリセットされる\n",
        "\n",
        "X_data = torch.tensor([[1.0, 2.0]])  # 入力データ（※再掲）\n",
        "y_pred = model(X_data)               # 出力結果（※再掲）\n",
        "y_true = torch.tensor([[1.0]])       # 正解ラベル\n",
        "\n",
        "criterion = nn.MSELoss()             # 誤差からの損失を測る「基準」＝損失関数\n",
        "loss = criterion(y_pred, y_true)     # 誤差（出力結果と正解ラベルの差）から損失を取得\n",
        "loss.backward()   # 逆伝播の処理として、勾配を計算（自動微分：Autograd）\n",
        "\n",
        "# 勾配の値（grad）は、各パラメーター（重みやバイアス）から取得できる\n",
        "print(model.layer1.weight.grad) # tensor([[-0.2002, -0.4005]])  ……などと表示される\n",
        "print(model.layer1.bias.grad)   # tensor([-0.2002])  ……などと表示される\n",
        "# ※パラメーターは「list(model.parameters())」で取得することも可能"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2002, -0.4005]])\n",
            "tensor([-0.2002])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvSX4RtIpx8U"
      },
      "source": [
        "このコードのポイント：\n",
        "- `criterion`に損失関数を代入するのが定石\n",
        "- `backward`メソッドによるバックプロパゲーション\n",
        "- この例では単純にするために1回しか処理してないが、本来はミニバッチのイテレーションや全体のエポックの回数繰り返し処理必要がある（第3回＝後述）\n",
        "- モデルにおける各パラメーター（`weight`や`bias`）の`grad`プロパティから、勾配の値は取得できる"
      ]
    }
  ]
}