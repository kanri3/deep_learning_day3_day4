{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_hands_on_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanri3/deep_learning_day3_day4/blob/main/pytorch_hands_on_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3nDS-MFxo06"
      },
      "source": [
        "### リスト1-1　ニューロンのモデル設計と活性化関数\n",
        "\n",
        "- ニューロンへの入力＝$(w_1 \\times X_1)+(w_2 \\times X_2)+b$\n",
        "- ニューロンからの出力＝$a((w_1 \\times X_1)+(w_2 \\times X_2)+b)$\n",
        "  - $a()$は活性化関数を意味する。つまりニューロンの入力結果を、活性化関数で変換したうえで、出力する\n",
        "  - 今回の活性化関数は、**tanh**関数とする\n",
        "- ニューロンの構造とデータ入力：座標$(X_1, X_2)$\n",
        "  - 入力の数（`INPUT_FEATURES`）は、$X_1$と$X_2$で**2つ**\n",
        "  - ニューロンの数（`OUTPUT_NEURONS`）は、**1つ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uu-jPQOxy2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7a4bde-6ae1-4b71-bc02-afadd15aa4a8"
      },
      "source": [
        "import torch       # ライブラリ「PyTorch」のtorchパッケージをインポート\n",
        "import torch.nn as nn  # 「ニューラルネットワーク」モジュールの別名定義\n",
        "\n",
        "# 定数（モデル定義時に必要となるもの）\n",
        "INPUT_FEATURES = 2  # 入力（特徴）の数： 2\n",
        "OUTPUT_NEURONS = 1  # ニューロンの数： 1\n",
        "\n",
        "# 変数（モデル定義時に必要となるもの）\n",
        "activation = torch.nn.Tanh()  # 活性化関数： tanh関数\n",
        "\n",
        "# 「torch.nn.Moduleクラスのサブクラス化」によるモデルの定義\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # 層（layer：レイヤー）を定義\n",
        "        self.layer1 = nn.Linear(  # Linearは「全結合層」を指す\n",
        "            INPUT_FEATURES,       # データ（特徴）の入力ユニット数\n",
        "            OUTPUT_NEURONS)       # 出力結果への出力ユニット数\n",
        "\n",
        "    def forward(self, input):\n",
        "        # フォワードパスを定義\n",
        "        output = activation(self.layer1(input))  # 活性化関数は変数として定義\n",
        "        # 「出力＝活性化関数（第n層（入力））」の形式で記述する。\n",
        "        # 層（layer）を重ねる場合は、同様の記述を続ければよい（第3回＝後述）。\n",
        "        # 「出力（output）」は次の層（layer）への「入力（input）」に使う。\n",
        "        # 慣例では入力も出力も「x」と同じ変数名で記述する（よって以下では「x」と書く）\n",
        "        return output\n",
        "\n",
        "# モデル（NeuralNetworkクラス）のインスタンス化\n",
        "model = NeuralNetwork()\n",
        "model   # モデルの内容を出力"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (layer1): Linear(in_features=2, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9COzxIQFzqJQ"
      },
      "source": [
        "このコードのポイント：\n",
        "- `torch.nn.Module`クラスを継承して独自にモデル用クラスを定義する。Pythonの「モジュール」と紛らわしいので、本稿では「`torch.nn.Module`」と表記する\n",
        "    - `__init__`関数にレイヤー（層）を定義する\n",
        "    - `forward`関数にフォワードパス（＝活性化関数で変換しながらデータを流す処理）を実装する\n",
        "    - ちなみにバックプロパゲーション（誤差逆伝播）のための`backward`関数は自動微分機能により自動作成される（後述）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQZPqNTzKvRI"
      },
      "source": [
        "# 第2回　PyTorchのテンソル＆データ型のチートシート"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dse8lpgMzeOQ"
      },
      "source": [
        "## ■（4）PyTorchの基礎： テンソルとデータ型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1twLZHGCsE_C"
      },
      "source": [
        "### 表4-1　PyTorchのデータ型\n",
        "\n",
        "先ほどのリスト1-3では、`torch.tensor([0.8])`というコードでPyTorchのテンソル（`torch.Tensor`値）を作成した。PyTorchでデータや数値を扱うには、このテンソル形式にする必要がある。  \n",
        "この例で分かるように、Pythonの数値やリスト値を`torch.Tensor`値に変換するのは難しくない。  \n",
        "ここでは、テンソルを作成／変換する基本的なコードをチートシート的に書き出しておく。  \n",
        "よく分からないところがあれば、下記の公式チュートリアルの説明を参照してほしい（※Chromeの［日本語に翻訳］機能を使えば、日本語で読める）。\n",
        "- 公式チュートリアル： [What is PyTorch? — PyTorch Tutorials 1.4.0 documentation](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)\n",
        "- APIドキュメント： [torch — PyTorch master documentation](https://pytorch.org/docs/stable/torch.html#tensors)\n",
        "\n",
        "また、テンソルの中に含める数値には、PyTorch独自のデータ型（`torch.dtypes`）がある。ただし統一データ型（ある1つのテンソル内に含まれる全要素の数値は全て同じデータ型）となっており、例えば`torch.float`の場合は、全ての要素の数値が「32-bitの浮動小数点」として扱われるので注意してほしい。基本的に`torch.float`か`torch.int`しか使わない。\n",
        "\n",
        "データ型 | dtype属性への記述 | 対応するPython／NumPy（np）のデータ型\n",
        "---------|-----------------|--------------------------------\n",
        "Boolean（真偽値）|torch.bool|bool／np.bool\n",
        "8-bitの符号なし整数|torch.uint8|int／np.uint8\n",
        "8-bitの符号付き整数|torch.int8|int／np.int8\n",
        "16-bitの符号付き整数|torch.int16 ／ torch.short|int／np.uint16\n",
        "32-bitの符号付き整数|torch.int32 ／ torch.int|int／np.uint32\n",
        "64-bitの符号付き整数|torch.int64 ／ torch.long|int／np.uint64\n",
        "16-bitの浮動小数点|torch.float16 ／ torch.half|float／np.float16\n",
        "32-bitの浮動小数点|torch.float32 ／ torch.float|float／np.float32\n",
        "64-bitの浮動小数点|torch.float64 ／ torch.double|float／np.float64\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e14rqQwrdLY"
      },
      "source": [
        "### リスト4-1　チートシート「テンソルの新規作成とサイズ取得／変換」"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThvwteuZBmpg"
      },
      "source": [
        "以下では、シンプルにテンソルの使い方だけを示すためため、`print(x)`などの出力に関するコードは極力、省略した。コードを実行して出力を確認したい場合は、例えば`x = torch.empty(2, 3)`というコードの後に`print(x)`を追記してほしい。また、`x.size()`というコードは、`print(x.size())`のように`print`関数を適宜、自分で補ってほしい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC8YGaH5wjh1"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# テンソルの新規作成\n",
        "x = torch.empty(2, 3) # 2行×3列のテンソル（未初期化状態）を生成\n",
        "x = torch.rand(2, 3)  # 2行×3列のテンソル（ランダムに初期化）を生成\n",
        "x = torch.zeros(2, 3, dtype=torch.float) # 2行×3列のテンソル（0で初期化、torch.float型）を生成\n",
        "x = torch.ones(2, 3, dtype=torch.float)  # 2行×3列のテンソル（1で初期化、torch.float型）を生成\n",
        "x = torch.tensor([[0.0, 0.1, 0.2],\n",
        "                  [1.0, 1.1, 1.2]])      # 1行×2列のテンソルをPythonリスト値から作成\n",
        "\n",
        "# 既存のテンソルを使った新規作成\n",
        "# 「new_*()」パターン\n",
        "y = x.new_ones(2, 3)   # 2行×3列のテンソル（1で初期化、既存のテンソルと「同じデータ型」）を生成\n",
        "# 「*_like()」パターン # 既存のテンソルと「同じサイズ」のテンソル（1で初期化、torch.int型）を生成\n",
        "y = torch.ones_like(x, dtype=torch.int) "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uhA6o7hwcgp"
      },
      "source": [
        "### リスト4-2　チートシート「テンソルのサイズ取得とサイズ変更」"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN_OWJbNr30Z"
      },
      "source": [
        "# テンソルサイズの取得\n",
        "x.size()               # 「torch.Size([2, 3])」のように、2行3列と出力される\n",
        "x.shape                # NumPy風の記述も可能。出力は上と同じ\n",
        "len(x)   # 行数（＝データ数）を取得する際も、NumPy風に記述することが可能\n",
        "x.ndim   # テンソルの次元数を取得する際も、NumPy風に記述が可能\n",
        "\n",
        "# テンソルのサイズ変更／形状変更\n",
        "z = x.view(3, 2)       # 3行2列に変更"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQGBrduXrvEv"
      },
      "source": [
        "### リスト4-3　チートシート「テンソルの演算／計算」"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pEm5IQOsGNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f29bb1-9f51-431a-e6e1-4fe8db2ad70a"
      },
      "source": [
        "# テンソルの計算操作\n",
        "x + y                  # 演算子を使う方法\n",
        "torch.add(x, y)        # 関数を使う方法\n",
        "torch.add(x, y, out=x) # outパラメーターで出力先の変数を指定可能\n",
        "x.add_(y)              # 「*_()」パターン。xを置き換えて出力する例（上記のコードと同じ処理）\n",
        "# PyTorchでは、メソッド名の最後にアンダースコア（_）がある場合（例えば「add_()」）、「テンソルの内部置き換え（in-place changes）が起こること」を意味する。\n",
        "# アンダースコア（_）がない通常の計算の場合（例えば「add()」）は、計算元のテンソル内部は変更されずに、戻り値として新たなテンソルが取得できる。"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.0000, 2.1000, 2.2000],\n",
              "        [3.0000, 3.1000, 3.2000]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TffYW0KgvaJb"
      },
      "source": [
        "### リスト4-4　チートシート「テンソルのインデクシング／スライシング」"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBMj5dYIveaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e1fbd5-82f7-4e60-c093-dc2e97012352"
      },
      "source": [
        "# インデクシングやスライシング（NumPyのような添え字を使用可能）\n",
        "print(x)         # 元は、2行3列のテンソル\n",
        "x[0, 1]          # 1行2列目（※0スタート）を取得\n",
        "x[:2, 1:]        # 先頭～2行（＝0行目と1行目）×2列～末尾（＝2列目と3列目）の2行2列が抽出される"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.0000, 2.1000, 2.2000],\n",
            "        [3.0000, 3.1000, 3.2000]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.1000, 2.2000],\n",
              "        [3.1000, 3.2000]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRWf1B-TwBRn"
      },
      "source": [
        "### リスト4-5　チートシート「テンソルからPython数値への変換」"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g7RxMDhwHYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7026073e-9baa-4066-c513-81d3fe617b43"
      },
      "source": [
        "# テンソルの1つの要素値を、Pythonの数値に変換\n",
        "x[0, 1].item()   # 1行2列目（※0スタート）の要素値をPythonの数値で取得"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0999999046325684"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-bw4KLMsDHc"
      },
      "source": [
        "### リスト4-6　チートシート「PyTorchテンソル ←→ NumPy多次元配列値、の変換＆連携」"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiJhYlYb12Kj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b73a76-9dd8-484b-f817-2dd8a06ce23b"
      },
      "source": [
        "# PyTorchテンソルを、NumPy多次元配列に変換\n",
        "b = x.numpy()    # 「numpy()」を呼び出すだけ。以下は注意点（メモリ位置の共有）\n",
        "\n",
        "# ※PyTorchテンソル側の値を変えると、NumPy多次元配列値「b」も変化する（トラックされる）\n",
        "print ('PyTorch計算→NumPy反映：')\n",
        "print(b); x.add_(y); print(b)           # PyTorch側の計算はNumPy側に反映\n",
        "print ('NumPy計算→PyTorch反映：')\n",
        "print(x); np.add(b, b, out=b); print(x) # NumPy側の計算はPyTorch側に反映\n",
        "\n",
        "# -----------------------------------------\n",
        "# NumPy多次元配列を、PyTorchテンソルに変換\n",
        "c = np.ones((2, 3), dtype=np.float64) # 2行3列の多次元配列値（1で初期化）を生成\n",
        "d = torch.from_numpy(c)  # 「torch.from_numpy()」を呼び出すだけ\n",
        "\n",
        "# ※NumPy多次元配列値を変えると、PyTorchテンソル「d」も変化する（トラックされる）\n",
        "print ('NumPy計算→PyTorch反映：')\n",
        "print(d); np.add(c, c, out=c); print(d)  # NumPy側の計算はPyTorch側に反映\n",
        "print ('PyTorch計算→NumPy反映：')\n",
        "print(c); d.add_(y); print(c)            # PyTorch側の計算はNumPy側に反映"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch計算→NumPy反映：\n",
            "[[2.  2.1 2.2]\n",
            " [3.  3.1 3.2]]\n",
            "[[3.  3.1 3.2]\n",
            " [4.  4.1 4.2]]\n",
            "NumPy計算→PyTorch反映：\n",
            "tensor([[3.0000, 3.1000, 3.2000],\n",
            "        [4.0000, 4.1000, 4.2000]])\n",
            "tensor([[6.0000, 6.2000, 6.4000],\n",
            "        [8.0000, 8.2000, 8.4000]])\n",
            "NumPy計算→PyTorch反映：\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]], dtype=torch.float64)\n",
            "PyTorch計算→NumPy反映：\n",
            "[[2. 2. 2.]\n",
            " [2. 2. 2.]]\n",
            "[[3. 3. 3.]\n",
            " [3. 3. 3.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASri35zKvjOV"
      },
      "source": [
        "### リスト4-7　チートシート「テンソルのデータ型の変換」"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4F1aW03v6OC"
      },
      "source": [
        "# データ型の変換（※変換後のテンソルには、NumPyの計算は反映されない）\n",
        "e = d.float()  # 「torch.float64」から「torch.float32」"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AWsYJ1Bvk9v"
      },
      "source": [
        "### リスト4-8　チートシート「テンソル演算でのGPU利用」"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLF66iayTPhd"
      },
      "source": [
        "ColabでGPUを有効にするには、メニューバーの［ランタイム］－［ランタイムのタイプを変更］をクリックして切り替えてほしい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_ABpMIEvqCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae45a74-b6ff-498f-e6a1-0b98be43abe2"
      },
      "source": [
        "# NVIDIAのGPUである「CUDA」（GPU）デバイス環境が利用可能な場合、\n",
        "# GPUを使ってテンソルの計算を行うこともできる\n",
        "if torch.cuda.is_available():              # CUDA（GPU）が利用可能な場合\n",
        "    print('CUDA（GPU）が利用できる環境')\n",
        "    print(f'CUDAデバイス数： {torch.cuda.device_count()}')\n",
        "    print(f'現在のCUDAデバイス番号： {torch.cuda.current_device()}')  # ※0スタート\n",
        "    print(f'1番目のCUDAデバイス名： {torch.cuda.get_device_name(0)}') # 例「Tesla T4」   \n",
        "\n",
        "    device = torch.device(\"cuda\")          # デフォルトのCUDAデバイスオブジェクトを取得\n",
        "    device0 = torch.device(\"cuda:0\")       # 1番目（※0スタート）のCUDAデバイスを取得\n",
        "\n",
        "    # テンソル計算でのGPUの使い方は主に3つ：\n",
        "    g = torch.ones(2, 3, device=device)    # （1）テンソル生成時のパラメーター指定\n",
        "    g = x.to(device)                       # （2）既存テンソルのデバイス変更\n",
        "    g = x.cuda(device)                     # （3）既存テンソルの「CUDA（GPU）」利用\n",
        "    f = x.cpu()                            # （3'）既存テンソルの「CPU」利用\n",
        "\n",
        "    # ※（2）の使い方で、GPUは「.to(\"cuda\")」、CPUは「.to(\"cpu\")」と書いてもよい\n",
        "    g = x.to(\"cuda\")\n",
        "    f = x.to(\"cpu\")\n",
        "\n",
        "    # ※（3）の引数は省略することも可能\n",
        "    g = x.cuda()\n",
        "\n",
        "    # 「torch.nn.Module」オブジェクト（model）全体でのGPU／CPUの切り替え\n",
        "    model.cuda()  # モデルの全パラメーターとバッファーを「CUDA（GPU）」に移行する\n",
        "    model.cpu()   # モデルの全パラメーターとバッファーを「CPU」に移行する\n",
        "else:\n",
        "    print('CUDA（GPU）が利用できない環境')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA（GPU）が利用できる環境\n",
            "CUDAデバイス数： 1\n",
            "現在のCUDAデバイス番号： 0\n",
            "1番目のCUDAデバイス名： Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}